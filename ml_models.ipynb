{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\agozacan\\\\OneDrive - Humberside Fire and Rescue Service\\\\RBIP Project\\\\Merged Data\\\\epc_irs_left_join.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cols = [\"ASSET_RATING\", \"ASSET_RATING_BAND\", \"PROPERTY_TYPE\", \"MAIN_HEATING_FUEL\", \"inc.2010\", \"inc.2011\", \"inc.2012\", \"inc.2013\",\n",
    "\"inc.2014\", \"inc.2015\", \"inc.2016\", \"inc.2017\",\n",
    "\"inc.2018\", \"inc.2019\", \"inc.2020\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[model_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field_name in [\"PROPERTY_TYPE\", \"MAIN_HEATING_FUEL\", \"ASSET_RATING_BAND\"]:\n",
    "    df[field_name] = df[field_name].replace(df[field_name].unique(), range(len(df[field_name].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(np.nan, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[df[\"inc.2020\"] > 0].index, \"inc.2020\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({\"inc.2020\": \"inc.2020.bool\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, test_set = train_test_split(df, test_size = 0.3)\n",
    "\n",
    "ncols = len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERSAMPLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OVERSAMPLE:\n",
    "\n",
    "    oversamp = ADASYN(sampling_strategy = 0.9)\n",
    "    # oversamp = SMOTE()\n",
    "    # oversamp = RandomOverSampler()\n",
    "\n",
    "    ncols = len(df.columns)\n",
    "\n",
    "    X, y = oversamp.fit_resample(training_set.iloc[:,:ncols-1], training_set.iloc[:,ncols-1])\n",
    "\n",
    "    training_set = pd.DataFrame(X)\n",
    "\n",
    "    training_set[\"inc.2020.bool\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11458"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_set.iloc[:,:ncols-1]\n",
    "y_train = training_set.iloc[:,ncols-1]\n",
    "X_test = test_set.iloc[:,:ncols-1]\n",
    "y_test = test_set.iloc[:,ncols-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agozacan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      2599\n",
      "         1.0       0.25      0.31      0.27        68\n",
      "\n",
      "    accuracy                           0.96      2667\n",
      "   macro avg       0.61      0.64      0.63      2667\n",
      "weighted avg       0.96      0.96      0.96      2667\n",
      "\n",
      "Random Forest:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97      2599\n",
      "         1.0       0.08      0.12      0.09        68\n",
      "\n",
      "    accuracy                           0.94      2667\n",
      "   macro avg       0.53      0.54      0.53      2667\n",
      "weighted avg       0.95      0.94      0.95      2667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier()\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "xgboost = GradientBoostingClassifier()\n",
    "xgboost.fit(X_train, y_train)\n",
    "\n",
    "y_ada_pred = adaboost.predict(X_test)\n",
    "test_set.insert(ncols, \"AdaBoost Predictions\", y_ada_pred)\n",
    "\n",
    "y_rf_pred = rf.predict(X_test)\n",
    "test_set.insert(ncols+1, \"RF Predictions\", y_rf_pred)\n",
    "\n",
    "y_lr_pred = logreg.predict(X_test)\n",
    "test_set.insert(ncols+2, \"LogReg Predictions\", y_lr_pred)\n",
    "\n",
    "y_xg_pred = xgboost.predict(X_test)\n",
    "test_set.insert(ncols+3, \"XGBoost Predictions\", y_xg_pred)\n",
    "\n",
    "print(\"AdaBoost:\", classification_report(test_set.iloc[:,ncols-1], test_set.iloc[:,ncols]))\n",
    "print(\"Random Forest:\", classification_report(test_set.iloc[:,ncols-1], test_set.iloc[:,ncols+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.92      0.95      2599\n",
      "         1.0       0.12      0.43      0.19        68\n",
      "\n",
      "    accuracy                           0.91      2667\n",
      "   macro avg       0.55      0.67      0.57      2667\n",
      "weighted avg       0.96      0.91      0.93      2667\n",
      "\n",
      "XGBoost:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      2599\n",
      "         1.0       0.26      0.26      0.26        68\n",
      "\n",
      "    accuracy                           0.96      2667\n",
      "   macro avg       0.62      0.62      0.62      2667\n",
      "weighted avg       0.96      0.96      0.96      2667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression:\", classification_report(test_set.iloc[:,ncols-1], test_set.iloc[:,ncols+2]))\n",
    "print(\"XGBoost:\", classification_report(test_set.iloc[:,ncols-1], test_set.iloc[:,ncols+3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Proportion Correctly Guessed: 0.9583802024746907\n",
      "Random Forest Proportion Correctly Guessed: 0.9418822647169104\n",
      "Logistic Regression Proportion Correctly Guessed: 0.9092613423322085\n",
      "XGBoost Proportion Correctly Guessed: 0.9625046869141357\n"
     ]
    }
   ],
   "source": [
    "length = len(test_set.iloc[:,ncols-1])\n",
    "\n",
    "ada_no_matched = sum([(test_set.iloc[i,ncols-1] * test_set.iloc[i,ncols]) + ((1-test_set.iloc[i,ncols-1]) * (1-test_set.iloc[i,ncols])) for i in range(length)])\n",
    "rf_no_matched = sum([(test_set.iloc[i,ncols-1] * test_set.iloc[i,ncols+1]) + ((1-test_set.iloc[i,ncols-1]) * (1-test_set.iloc[i,ncols+1])) for i in range(length)])\n",
    "lr_no_matched = sum([(test_set.iloc[i,ncols-1] * test_set.iloc[i,ncols+2]) + ((1-test_set.iloc[i,ncols-1]) * (1-test_set.iloc[i,ncols+2])) for i in range(length)])\n",
    "xg_no_matched = sum([(test_set.iloc[i,ncols-1] * test_set.iloc[i,ncols+3]) + ((1-test_set.iloc[i,ncols-1]) * (1-test_set.iloc[i,ncols+3])) for i in range(length)])\n",
    "\n",
    "ada_accuracy = ada_no_matched / length\n",
    "rf_accuracy = rf_no_matched / length\n",
    "lr_accuracy = lr_no_matched / length\n",
    "xg_accuracy = xg_no_matched / length\n",
    "\n",
    "print(\"AdaBoost Proportion Correctly Guessed:\", ada_accuracy)\n",
    "print(\"Random Forest Proportion Correctly Guessed:\", rf_accuracy)\n",
    "print(\"Logistic Regression Proportion Correctly Guessed:\", lr_accuracy)\n",
    "print(\"XGBoost Proportion Correctly Guessed:\", xg_accuracy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14eabb916c6544ec72073d369246e9786cf732268ebd379f4cd554d89eecb526"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
