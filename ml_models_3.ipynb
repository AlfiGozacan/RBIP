{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\agozacan\\\\OneDrive - Humberside Fire and Rescue Service\\\\RBIP Project\\\\Merged Data\\\\risk_join.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cols = [\"RISK_OF_FIRE\", \"SEVERITY_OF_FIRE\", \"SLEEPING_RISK\", \"SLEEPING_RISK_ABOVE\", \"SSRI_SCORE\",\n",
    "\"FSEC_DESCRIPT\", \"GRS\", \"FIRE SAFETY STATUS\",\n",
    "\"Satisfactory\", \"ASSET_RATING\", \"ASSET_RATING_BAND\", \"PROPERTY_TYPE\", \"MAIN_HEATING_FUEL\", \"inc.2010\", \"inc.2011\", \"inc.2012\", \"inc.2013\",\n",
    "\"inc.2014\", \"inc.2015\", \"inc.2016\", \"inc.2017\",\n",
    "\"inc.2018\", \"inc.2019\", \"inc.2020\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"FIRE SAFETY STATUS\"] = df[\"FIRE SAFETY STATUS\"].replace([\"(1) Well Above Average\", \"(2) Above Average\", \"(3) Average\", \"(4) Below Average\", \"(5) Very Below Average\"], range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ASSET_RATING_BAND\"] = df[\"ASSET_RATING_BAND\"].replace([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"], range(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"SLEEPING_RISK\", \"FSEC_DESCRIPT\", \"Satisfactory\", \"PROPERTY_TYPE\", \"MAIN_HEATING_FUEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[model_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(np.nan, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[df[\"inc.2020\"] > 0].index, \"inc.2020\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({\"inc.2020\": \"inc.2020.bool\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(drop=\"first\", sparse=False)\n",
    "\n",
    "dummy_view = encoder.fit_transform(df[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.DataFrame(dummy_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df.columns = encoder.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(categorical_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encoded_df.join(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"inc.2020.bool\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"C:\\\\Users\\\\agozacan\\\\OneDrive - Humberside Fire and Rescue Service\\\\RBIP Project\\\\Merged Data\\\\clean_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, test_set = train_test_split(df, test_size = 0.33)\n",
    "\n",
    "ncols = len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERSAMPLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OVERSAMPLE:\n",
    "\n",
    "    # oversamp = ADASYN()\n",
    "    # oversamp = SMOTE(sampling_strategy=0.9)\n",
    "    oversamp = RandomOverSampler()\n",
    "\n",
    "    ncols = len(df.columns)\n",
    "\n",
    "    X, y = oversamp.fit_resample(training_set.iloc[:,:-1], training_set.iloc[:,-1])\n",
    "\n",
    "    training_set = pd.DataFrame(X)\n",
    "\n",
    "    training_set[\"inc.2020.bool\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_set.iloc[:,:-1]\n",
    "y_train = training_set.iloc[:,-1]\n",
    "X_test = test_set.iloc[:,:-1]\n",
    "y_test = test_set.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = AdaBoostClassifier()\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "xgboost = GradientBoostingClassifier()\n",
    "xgboost.fit(X_train, y_train)\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_ada_pred = adaboost.predict(X_test)\n",
    "test_set.insert(ncols, \"AdaBoost Predictions\", y_ada_pred)\n",
    "\n",
    "y_rf_pred = rf.predict(X_test)\n",
    "test_set.insert(ncols+1, \"RF Predictions\", y_rf_pred)\n",
    "\n",
    "y_lr_pred = logreg.predict(X_test)\n",
    "test_set.insert(ncols+2, \"LogReg Predictions\", y_lr_pred)\n",
    "\n",
    "y_xg_pred = xgboost.predict(X_test)\n",
    "test_set.insert(ncols+3, \"XGBoost Predictions\", y_xg_pred)\n",
    "\n",
    "y_mlp_pred = mlp.predict(X_test)\n",
    "test_set.insert(ncols+4, \"MLP Predictions\", y_mlp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[test_set[\"inc.2020.bool\"] == 1.0].iloc[:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_positives = len(test_set[test_set[\"inc.2020.bool\"] == 1.0])\n",
    "adaboost_positives = len(test_set[test_set[\"AdaBoost Predictions\"] == 1.0])\n",
    "rf_positives = len(test_set[test_set[\"RF Predictions\"] == 1.0])\n",
    "logreg_positives = len(test_set[test_set[\"LogReg Predictions\"] == 1.0])\n",
    "XGBoost_positives = len(test_set[test_set[\"XGBoost Predictions\"] == 1.0])\n",
    "MLP_positives = len(test_set[test_set[\"MLP Predictions\"] == 1.0])\n",
    "\n",
    "print(f\"There are {len(test_set)} entries in the test set, of which {real_positives} are real positives\")\n",
    "print(f\"AdaBoost predicted {adaboost_positives} positives\")\n",
    "print(f\"Random Forest predicted {rf_positives} positives\")\n",
    "print(f\"Logistic Regression predicted {logreg_positives} positives\")\n",
    "print(f\"XGBoost predicted {XGBoost_positives} positives\")\n",
    "print(f\"MLP predicted {MLP_positives} positives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"AdaBoost:\", classification_report(test_set.iloc[:,ncols-1], test_set.iloc[:,ncols]))\n",
    "print(\"Random Forest:\", classification_report(test_set.iloc[:,ncols-1], test_set.iloc[:,ncols+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Logistic Regression:\", classification_report(test_set.iloc[:,ncols-1], test_set.iloc[:,ncols+2]))\n",
    "print(\"XGBoost:\", classification_report(test_set.iloc[:,ncols-1], test_set.iloc[:,ncols+3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLP:\", classification_report(test_set.iloc[:,ncols-1], test_set.iloc[:,ncols+4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "length = len(test_set.iloc[:,ncols-1])\n",
    "\n",
    "ada_no_matched = sum([(test_set.iloc[i,ncols-1] * test_set.iloc[i,ncols]) + ((1-test_set.iloc[i,ncols-1]) * (1-test_set.iloc[i,ncols])) for i in range(length)])\n",
    "rf_no_matched = sum([(test_set.iloc[i,ncols-1] * test_set.iloc[i,ncols+1]) + ((1-test_set.iloc[i,ncols-1]) * (1-test_set.iloc[i,ncols+1])) for i in range(length)])\n",
    "lr_no_matched = sum([(test_set.iloc[i,ncols-1] * test_set.iloc[i,ncols+2]) + ((1-test_set.iloc[i,ncols-1]) * (1-test_set.iloc[i,ncols+2])) for i in range(length)])\n",
    "xg_no_matched = sum([(test_set.iloc[i,ncols-1] * test_set.iloc[i,ncols+3]) + ((1-test_set.iloc[i,ncols-1]) * (1-test_set.iloc[i,ncols+3])) for i in range(length)])\n",
    "mlp_no_matched = sum([(test_set.iloc[i,ncols-1] * test_set.iloc[i,ncols+4]) + ((1-test_set.iloc[i,ncols-1]) * (1-test_set.iloc[i,ncols+4])) for i in range(length)])\n",
    "\n",
    "ada_accuracy = ada_no_matched / length\n",
    "rf_accuracy = rf_no_matched / length\n",
    "lr_accuracy = lr_no_matched / length\n",
    "xg_accuracy = xg_no_matched / length\n",
    "mlp_accuracy = mlp_no_matched / length\n",
    "\n",
    "print(\"AdaBoost Proportion Correctly Guessed:\", ada_accuracy)\n",
    "print(\"Random Forest Proportion Correctly Guessed:\", rf_accuracy)\n",
    "print(\"Logistic Regression Proportion Correctly Guessed:\", lr_accuracy)\n",
    "print(\"XGBoost Proportion Correctly Guessed:\", xg_accuracy)\n",
    "print(\"MLP Proportion Correctly Guessed:\", mlp_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaprobs = adaboost.predict_proba(X_test)\n",
    "rfprobs = rf.predict_proba(X_test)\n",
    "lrprobs = logreg.predict_proba(X_test)\n",
    "xgprobs = xgboost.predict_proba(X_test)\n",
    "mlpprobs = mlp.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PLOTS\n",
    "\n",
    "probas = [adaprobs, rfprobs, lrprobs, xgprobs, mlpprobs]\n",
    "titles = [\"AdaBoost\", \"Random Forest\", \"Logistic Regression\", \"XGBoost\", \"MLP\"]\n",
    "\n",
    "for i in range(len(probas)):\n",
    "    \n",
    "    skplt.metrics.plot_roc(y_test, probas[i], title=titles[i])\n",
    "\n",
    "    # plt.savefig(\"C:\\\\Users\\\\agozacan\\\\OneDrive - Humberside Fire and Rescue Service\\\\RBIP Project\\\\Report\\\\images\\\\\"+titles[i]+\"_ROC.png\", dpi = 200, bbox_inches = \"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive_probs = [x[1] for x in adaprobs]  # THIS CODE SNIPPET IS IN CASE YOU WANT TO SPLIT INTO QUARTILES\n",
    "# positive_probs_assigned = [p for p in positive_probs if p > 0.5]\n",
    "# positive_indices = [positive_probs.index(y) for y in positive_probs_assigned]\n",
    "# test_set.reset_index(drop=True, inplace=True)\n",
    "# test_set.loc[positive_indices, \"quartile\"] = pd.qcut(positive_probs_assigned, q=4, labels=[4, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = rf.feature_importances_\n",
    "\n",
    "ftrs = pd.DataFrame({\"column_name\": df.columns[:-1], \"score\": features}).sort_values(by = \"score\", ascending = False).reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(y = ftrs.loc[:15, \"column_name\"], x = ftrs.loc[:15, \"score\"])\n",
    "plt.title(\"Random Forest Feature Importance\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Column Names\")\n",
    "# plt.savefig(\"C:\\\\Users\\\\agozacan\\\\OneDrive - Humberside Fire and Rescue Service\\\\RBIP Project\\\\Report\\\\Images\\\\rf_features.png\", dpi = 200, bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14eabb916c6544ec72073d369246e9786cf732268ebd379f4cd554d89eecb526"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
